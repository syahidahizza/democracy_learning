{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from functools import partial\n",
    "from attacks import fgm, jsma, deepfool, cw\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, sess, logits=False, training=False):\n",
    "    with sess.graph.as_default() :\n",
    "        with tf.variable_scope('conv0'):\n",
    "            z = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n",
    "                                 padding='same', activation=tf.nn.relu)\n",
    "            z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        with tf.variable_scope('flatten'):\n",
    "            shape = z.get_shape().as_list()\n",
    "            z = tf.reshape(z, [-1, np.prod(shape[1:])])\n",
    "\n",
    "        with tf.variable_scope('mlp0'):\n",
    "            z = tf.layers.dense(z, units=256, activation=tf.nn.relu)\n",
    "\n",
    "        logits_ = tf.layers.dense(z, units=10, name='logits')\n",
    "        y = tf.nn.softmax(logits_, name='ybar')\n",
    "\n",
    "        if logits:\n",
    "            return y, logits_\n",
    "        return y\n",
    "def evaluate(sess, env, X_data, y_data, batch_size=batch_size):\n",
    "    \"\"\"\n",
    "    Evaluate TF model by running env.loss and env.acc.\n",
    "    \"\"\"\n",
    "    print('\\nEvaluating')\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    loss, acc = 0, 0\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        cnt = end - start\n",
    "        batch_loss, batch_acc = sess.run(\n",
    "            [env.loss, env.acc],\n",
    "            feed_dict={env.x: X_data[start:end],\n",
    "                       env.y: y_data[start:end]})\n",
    "        loss += batch_loss * cnt\n",
    "        acc += batch_acc * cnt\n",
    "    loss /= n_sample\n",
    "    acc /= n_sample\n",
    "\n",
    "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def train(sess, env, X_data, y_data, X_valid=None, y_valid=None, epochs=1,\n",
    "          load=False, shuffle=True, batch_size=batch_size, name='model', \n",
    "          train_method = 'normal', debug=False):\n",
    "    \"\"\"\n",
    "    Train a TF model by running env.train_op.\n",
    "    \"\"\"\n",
    "    if load:\n",
    "        if not hasattr(env, 'saver'):\n",
    "            return print('\\nError: cannot find saver op')\n",
    "        print('\\nLoading saved model')\n",
    "        return env.saver.restore(sess, 'model_pilot/{}'.format(name))\n",
    "\n",
    "    print('\\nTrain model')\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        print('\\nEpoch {0}/{1}'.format(epoch + 1, epochs))\n",
    "\n",
    "        if shuffle:\n",
    "            print('\\nShuffling data')\n",
    "            ind = np.arange(n_sample)\n",
    "            np.random.shuffle(ind)\n",
    "            X_data = X_data[ind]\n",
    "            y_data = y_data[ind]\n",
    "\n",
    "        for batch in range(n_batch):\n",
    "            print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "            start = batch * batch_size\n",
    "            end = min(n_sample, start + batch_size)\n",
    "            if train_method != 'normal':\n",
    "                ybar_t_1 = sess.run(env.ybar, \n",
    "                                    feed_dict={env.x: X_data[start:end],\n",
    "                                                  env.y: y_data[start:end],\n",
    "                                                  env.training: False})\n",
    "                \n",
    "            if debug :\n",
    "                print('=============ybar_t_1===================')\n",
    "                print(ybar_t_1)\n",
    "                print('************y_data_t_1*************')\n",
    "                print(y_data[start:end])\n",
    "                \n",
    "            [_]=sess.run([env.train_op], feed_dict={env.x: X_data[start:end],\n",
    "                                              env.y: y_data[start:end],\n",
    "                                              env.training: True})\n",
    "            if train_method != 'normal':\n",
    "                ybar_t=sess.run(env.ybar, feed_dict={env.x: X_data[start:end],\n",
    "                                                  env.y: y_data[start:end],\n",
    "                                                  env.training: False})\n",
    "                y_next_t = update_y(ybar_t_1, ybar_t,y_data[start:end])\n",
    "                \n",
    "                if debug :\n",
    "                    print('------------------ybar_t----------------------------')\n",
    "                    print(ybar_t)\n",
    "                    print('------------------ynext_t----------------------------')\n",
    "                    print(y_next_t)\n",
    "                    print('++++++++++++++y_data_t++++++++++++')\n",
    "                \n",
    "                y_data[start:end] = y_next_t\n",
    "            \n",
    "        if X_valid is not None:\n",
    "            evaluate(sess, env, X_valid, y_valid)\n",
    "\n",
    "    if hasattr(env, 'saver'):\n",
    "        print('\\n Saving model')\n",
    "        os.makedirs('model_pilot', exist_ok=True)\n",
    "        env.saver.save(sess, 'model_pilot/{}'.format(name))\n",
    "        \n",
    "    return y_data\n",
    "\n",
    "def predict(sess, env, X_data, batch_size=batch_size, need_logit=False):\n",
    "    \"\"\"\n",
    "    Do inference by running env.ybar.\n",
    "    \"\"\"\n",
    "    print('\\nPredicting')\n",
    "    n_classes = env.ybar.get_shape().as_list()[1]\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    yval = np.empty((n_sample, n_classes))\n",
    "    logits = np.empty((n_sample, n_classes))\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        if not need_logit:\n",
    "            y_batch = sess.run(env.ybar, feed_dict={env.x: X_data[start:end]})\n",
    "            yval[start:end] = y_batch\n",
    "        else:\n",
    "            [y_batch,logit_batch] = sess.run(env.ybar, feed_dict={env.x: X_data[start:end]})\n",
    "            yval[start:end] = y_batch\n",
    "            logits[start:end] = logit_batch\n",
    "    return yval\n",
    "\n",
    "def update_y(ybar_old, ybar_current, y_target, alpha=alpha, w_target=w_target) :\n",
    "    prev_bar = ybar_old + alpha*(ybar_current - ybar_old)\n",
    "    prev_bar = np.minimum(np.maximum(prev_bar, np.zeros(prev_bar.shape)), np.ones(prev_bar.shape))  \n",
    "    y_new = (1-w_target)*prev_bar/np.sum(prev_bar, axis=1, keepdims=True) + y_target*w_target\n",
    "    return y_new\n",
    "\n",
    "class Environment:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fgsm(sess, env, X_data, epochs=1, eps=0.01, batch_size=batch_size):\n",
    "    print('\\nMaking adversarials via FGSM')\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample + batch_size - 1) / batch_size)\n",
    "    X_adv = np.empty_like(X_data)\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        feed_dict = {env.x: X_data[start:end], env.adv_eps: eps,\n",
    "                     env.adv_epochs: epochs}\n",
    "        adv = sess.run(env.x_fgsm, feed_dict=feed_dict)\n",
    "        X_adv[start:end] = adv\n",
    "    print()\n",
    "\n",
    "    return X_adv\n",
    "\n",
    "\n",
    "def make_jsma(sess, env, X_data, epochs=0.2, eps=1.0, batch_size=batch_size):\n",
    "    print('\\nMaking adversarials via JSMA')\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample + batch_size - 1) / batch_size)\n",
    "    X_adv = np.empty_like(X_data)\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        feed_dict = {\n",
    "            env.x: X_data[start:end],\n",
    "            env.adv_y: np.random.choice(n_classes),\n",
    "            env.adv_epochs: epochs,\n",
    "            env.adv_eps: eps}\n",
    "        adv = sess.run(env.x_jsma, feed_dict=feed_dict)\n",
    "        X_adv[start:end] = adv\n",
    "    print()\n",
    "\n",
    "    return X_adv\n",
    "\n",
    "\n",
    "def make_deepfool(sess, env, X_data, epochs=1, eps=0.01, batch_size=128):\n",
    "    print('\\nMaking adversarials via FGSM')\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample + batch_size - 1) / batch_size)\n",
    "    X_adv = np.empty_like(X_data)\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        feed_dict = {env.x: X_data[start:end], env.adv_epochs: epochs,\n",
    "                      env.adv_eps:eps}\n",
    "        adv = sess.run(env.x_deepfool, feed_dict=feed_dict)\n",
    "        X_adv[start:end] = adv\n",
    "    print()\n",
    "\n",
    "    return X_adv\n",
    "\n",
    "def make_cw(env, X_data, epochs=1, eps=0.1, batch_size=batch_size):\n",
    "    \"\"\"\n",
    "    Generate adversarial via CW optimization.\n",
    "    \"\"\"\n",
    "    print('\\nMaking adversarials via CW')\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample + batch_size - 1) / batch_size)\n",
    "    X_adv = np.empty_like(X_data)\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        end = min(n_sample, (batch+1) * batch_size)\n",
    "        start = end - batch_size\n",
    "        feed_dict = {\n",
    "            env.x_fixed: X_data[start:end],\n",
    "            env.adv_eps: eps,\n",
    "            env.adv_y: np.random.choice(n_classes)}\n",
    "\n",
    "        # reset the noise before every iteration\n",
    "        env.sess.run(env.cw_noise.initializer)\n",
    "        for epoch in range(epochs):\n",
    "            env.sess.run(env.cw_adv_train_op, feed_dict=feed_dict)\n",
    "\n",
    "        xadv = env.sess.run(env.cw_xadv, feed_dict=feed_dict)\n",
    "        X_adv[start:end] = xadv\n",
    "\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_method='normal'\n",
    "method='1.1'\n",
    "alpha = 10\n",
    "w_target = 0.9\n",
    "\n",
    "img_size = 28\n",
    "img_chan = 1\n",
    "n_classes = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(env, sess) :\n",
    "    with sess.graph.as_default() :\n",
    "        with tf.variable_scope('model'):\n",
    "            env.x = tf.placeholder(tf.float32, (None, img_size, img_size, img_chan),\n",
    "                                   name='x')\n",
    "            env.y = tf.placeholder(tf.float32, (None, n_classes), name='y')\n",
    "            env.training = tf.placeholder_with_default(False, (), name='mode')\n",
    "\n",
    "            env.ybar, env.logits = model(env.x, sess, logits=True, training=env.training)\n",
    "\n",
    "            with tf.variable_scope('acc'):\n",
    "                count = tf.equal(tf.argmax(env.y, axis=1), tf.argmax(env.ybar, axis=1))\n",
    "                env.acc = tf.reduce_mean(tf.cast(count, tf.float32), name='acc')\n",
    "\n",
    "            with tf.variable_scope('loss'):\n",
    "                xent = tf.nn.softmax_cross_entropy_with_logits(labels=env.y,\n",
    "                                                               logits=env.logits)\n",
    "                env.loss = tf.reduce_mean(xent, name='loss')\n",
    "\n",
    "            with tf.variable_scope('train_op'):\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate = 0.1,\n",
    "                                                      momentum=0.1)\n",
    "                env.train_op = optimizer.minimize(env.loss)\n",
    "\n",
    "            env.saver = tf.train.Saver()\n",
    "\n",
    "        with tf.variable_scope('model', reuse=tf.AUTO_REUSE):\n",
    "            env.adv_eps = tf.placeholder(tf.float32, (), name='adv_eps')\n",
    "            env.adv_epochs = tf.placeholder(tf.int32, (), name='adv_epochs')\n",
    "            env.adv_y = tf.placeholder(tf.int32, (), name='adv_y')\n",
    "\n",
    "            partial_model = partial(model, sess=sess)\n",
    "            env.x_fgsm = fgm(partial_model, env.x, epochs=env.adv_epochs, eps=env.adv_eps)\n",
    "            env.x_deepfool = deepfool(partial_model, env.x, epochs=env.adv_epochs, \n",
    "                                      eta=env.adv_eps,batch=True)\n",
    "            env.x_jsma = jsma(partial_model, env.x, env.adv_y, eps=env.adv_eps,\n",
    "                              epochs=env.adv_epochs)\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "            env.x_fixed = tf.placeholder(tf.float32, (batch_size, img_size, img_size, img_chan), name='x_fixed')\n",
    "            env.cw_adv_train_op, env.cw_xadv, env.cw_noise = cw(partial_model, env.x_fixed,\n",
    "                                                       y=env.adv_y, eps=env.adv_eps,\n",
    "                                                       optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading MNIST')\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = np.reshape(X_train, [-1, img_size, img_size, img_chan])\n",
    "X_train = X_train.astype(np.float32) / 255\n",
    "X_test = np.reshape(X_test, [-1, img_size, img_size, img_chan])\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "\n",
    "to_categorical = tf.keras.utils.to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_train_origin = np.array(y_train)\n",
    "\n",
    "pw = 5\n",
    "single_weight = 1/(n_classes-1+pw)\n",
    "y_train_t_0 = np.array([(y * (pw-1) * single_weight) + single_weight for y in y_train])\n",
    "\n",
    "print('Spliting data')\n",
    "\n",
    "if train_method!='normal':\n",
    "    y_train = np.array(y_train_t_0)\n",
    "\n",
    "ind = np.random.permutation(X_train.shape[0])\n",
    "X_train, y_train = X_train[ind], y_train[ind]\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "n = int(X_train.shape[0] * (1-VALIDATION_SPLIT))\n",
    "X_valid = X_train[n:]\n",
    "X_train = X_train[:n]\n",
    "y_valid = y_train[n:]\n",
    "y_train = y_train[:n]\n",
    "y_origin = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_sess = tf.InteractiveSession(config=config, graph=tf.Graph())\n",
    "teacher_env = Environment()\n",
    "teacher_env.sess = teacher_sess\n",
    "\n",
    "generate_graph(teacher_env, teacher_sess)\n",
    "teacher_sess.run(tf.global_variables_initializer())\n",
    "teacher_sess.run(tf.local_variables_initializer())\n",
    "\n",
    "print('Training Teacher')\n",
    "y_data = train(teacher_sess, teacher_env, X_train, y_train, X_valid, y_valid, load=True, \n",
    "               epochs=30, shuffle=False, name='mnist_teacher_adding_deepfool',train_method=\"normal\")\n",
    "\n",
    "evaluate(teacher_sess, teacher_env, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_candidate_cw = [1.5**i * 1e-4 for i in (list(range(3,23)))]\n",
    "eps_candidate_fgsm = [(0.001*i+0.0015) for i in (list(range(0,20)))]\n",
    "eps_candidate_jsma = [(0.1*i+0.15) for i in (list(range(0,20)))]\n",
    "eps_candidate_deepfool = [i * 1e-1 - 1.1 for i in (list(range(1,21)))]\n",
    "\n",
    "T_x_fgsm_res = []\n",
    "T_x_jsma_res = []\n",
    "T_X_cw_res = []\n",
    "T_X_deepfool_res = []\n",
    "\n",
    "for (eps_cw,eps_fgsm,eps_jsma,eps_deepfool) in zip(eps_candidate_cw,eps_candidate_fgsm,eps_candidate_jsma,eps_candidate_deepfool):\n",
    "    x_fgsm_advs = make_fgsm(teacher_sess, teacher_env, X_test, eps=eps_fgsm, epochs=10)\n",
    "    result = evaluate(teacher_sess, teacher_env, x_fgsm_advs, y_test)\n",
    "    T_x_fgsm_res.append(result[1])\n",
    "    x_jsma_advs = make_jsma(teacher_sess, teacher_env, X_test, eps=eps_jsma, epochs=40)\n",
    "    result = evaluate(teacher_sess, teacher_env, x_jsma_advs, y_test)\n",
    "    T_x_jsma_res.append(result[1])\n",
    "    X_cw = make_cw(teacher_env, X_test, eps=eps_cw, epochs=100)\n",
    "    result = evaluate(teacher_sess, teacher_env, X_cw, y_test)\n",
    "    T_X_cw_res.append(result[1])\n",
    "    x_deepfool_advs = make_deepfool(teacher_sess, teacher_env, X_test, eps=eps_deepfool, epochs=10)\n",
    "    result = evaluate(democracy_learning_sess, democracy_learning_env, x_deepfool_advs, y_test)\n",
    "    T_X_deepfool_res.append(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating label for student')\n",
    "y_train_logit = predict(teacher_sess, teacher_env, X_train)\n",
    "ind = np.random.permutation(X_train.shape[0])\n",
    "X_train, y_train_logit = X_train[ind], y_train_logit[ind]\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "n = int(X_train.shape[0] * (1-VALIDATION_SPLIT))\n",
    "X_valid = X_train[n:]\n",
    "X_train = X_train[:n]\n",
    "y_valid_logit = y_train_logit[n:]\n",
    "y_train_logit = y_train_logit[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_sess = tf.InteractiveSession(config=config, graph=tf.Graph())\n",
    "student_env = Environment()\n",
    "student_env.sess = student_sess\n",
    "\n",
    "generate_graph(student_env, student_sess)\n",
    "student_sess.run(tf.global_variables_initializer())\n",
    "student_sess.run(tf.local_variables_initializer())\n",
    "\n",
    "print('Training Student')\n",
    "y_data = train(student_sess, student_env, X_train, y_train_logit, X_valid, y_valid_logit, load=True, \n",
    "               epochs=30, shuffle=False, name='mnist_student_adding_deepfool',train_method=\"normal\")\n",
    "evaluate(student_sess, student_env, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_x_fgsm_res = []\n",
    "S_x_jsma_res = []\n",
    "S_X_cw_res = []\n",
    "S_X_deepfool_res = []\n",
    "\n",
    "for (eps_cw,eps_fgsm,eps_jsma,eps_deepfool) in zip(eps_candidate_cw,eps_candidate_fgsm,eps_candidate_jsma,eps_candidate_deepfool):\n",
    "    x_fgsm_advs = make_fgsm(student_sess, student_env, X_test, eps=eps_fgsm, epochs=10)\n",
    "    result = evaluate(student_sess, student_env, x_fgsm_advs, y_test)\n",
    "    S_x_fgsm_res.append(result[1])\n",
    "    x_jsma_advs = make_jsma(student_sess, student_env, X_test, eps=eps_jsma, epochs=40)\n",
    "    result = evaluate(student_sess, student_env, x_jsma_advs, y_test)\n",
    "    S_x_jsma_res.append(result[1])\n",
    "    X_cw = make_cw(student_env, X_test, eps=eps_cw, epochs=100)\n",
    "    result = evaluate(student_sess, student_env, X_cw, y_test)\n",
    "    S_X_cw_res.append(result[1])\n",
    "    x_deepfool_advs = make_deepfool(student_sess, student_env, X_test, eps=eps_deepfool, epochs=10)\n",
    "    result = evaluate(democracy_learning_sess, democracy_learning_env, x_deepfool_advs, y_test)\n",
    "    S_X_deepfool_res.append(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "democracy_learning_sess = tf.InteractiveSession(config=config, graph=tf.Graph())\n",
    "democracy_learning_env = Environment()\n",
    "democracy_learning_env.sess = democracy_learning_sess\n",
    "\n",
    "generate_graph(democracy_learning_env, democracy_learning_sess)\n",
    "democracy_learning_sess.run(tf.global_variables_initializer())\n",
    "democracy_learning_sess.run(tf.local_variables_initializer())\n",
    "\n",
    "print('\\nTraining')\n",
    "print(alpha)\n",
    "print(w_target)\n",
    "print(pw)\n",
    "\n",
    "y_data = train(democracy_learning_sess, democracy_learning_env, X_train, y_train, X_valid, y_valid, \n",
    "               load=False, epochs=30, shuffle=False, \n",
    "               name='mnist_method_adding_deepfool_near_normal_w_target_0.9_pw_30'+method,method=\"1.1\")\n",
    "\n",
    "evaluate(democracy_learning_sess, democracy_learning_env, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fgsm_res = []\n",
    "x_jsma_res = []\n",
    "X_cw_res = []\n",
    "X_deepfool_res = []\n",
    "for (eps_cw,eps_fgsm,eps_jsma,eps_deepfool) in zip(eps_candidate_cw,eps_candidate_fgsm,eps_candidate_jsma,eps_candidate_deepfool):\n",
    "    x_fgsm_advs = make_fgsm(democracy_learning_sess, democracy_learning_env, X_test, eps=eps_fgsm, epochs=10)\n",
    "    result = evaluate(democracy_learning_sess, democracy_learning_env, x_fgsm_advs, y_test)\n",
    "    x_fgsm_res.append(result[1])\n",
    "    x_jsma_advs = make_jsma(democracy_learning_sess, democracy_learning_env, X_test, eps=eps_jsma, epochs=40)\n",
    "    result = evaluate(democracy_learning_sess, democracy_learning_env, x_jsma_advs, y_test)\n",
    "    x_jsma_res.append(result[1])\n",
    "    X_cw = make_cw(democracy_learning_env, X_test, eps=eps_cw, epochs=100)\n",
    "    result = evaluate(democracy_learning_sess, democracy_learning_env, X_cw, y_test)\n",
    "    X_cw_res.append(result[1])\n",
    "    x_deepfool_advs = make_deepfool(democracy_learning_sess, democracy_learning_env, X_test,eps=eps_deepfool, epochs=10)\n",
    "    result = evaluate(democracy_learning_sess, democracy_learning_env, x_deepfool_advs, y_test)\n",
    "    X_deepfool_res.append(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(20,10))\n",
    "cw_plot = fig1.add_subplot(111)\n",
    "cw_plot.plot(T_X_cw_res,label='teacher')\n",
    "cw_plot.plot(S_X_cw_res,label='student')\n",
    "cw_plot.plot(X_cw_res,label='our method')\n",
    "cw_plot.legend(loc=3)\n",
    "\n",
    "fig2 = plt.figure(figsize=(20,10))\n",
    "fgsm_plot = fig2.add_subplot(111)\n",
    "fgsm_plot.plot(T_x_fgsm_res,label='teacher')\n",
    "fgsm_plot.plot(S_x_fgsm_res,label='student')\n",
    "fgsm_plot.plot(x_fgsm_res,label='our method')\n",
    "fgsm_plot.legend(loc=3)\n",
    "\n",
    "fig3 = plt.figure(figsize=(20,10))\n",
    "jsma_plot = fig3.add_subplot(111)\n",
    "jsma_plot.plot(T_x_jsma_res,label='teacher')\n",
    "jsma_plot.plot(S_x_jsma_res,label='student')\n",
    "jsma_plot.plot(x_jsma_res,label='our method')\n",
    "jsma_plot.legend(loc=3)\n",
    "\n",
    "fig3 = plt.figure(figsize=(20,10))\n",
    "deepfool_plot = fig3.add_subplot(111)\n",
    "deepfool_plot.plot(T_x_deepfool_res,label='teacher')\n",
    "deepfool_plot.plot(S_x_deepfool_res,label='student')\n",
    "deepfool_plot.plot(x_deepfool_res,label='our method')\n",
    "deepfool_plot.legend(loc=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
